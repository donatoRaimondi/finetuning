{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch e CUDA\n",
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Transformers e Training\n",
    "from transformers import (\n",
    "    TextStreamer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# Dataset e valutazione\n",
    "from datasets import load_dataset, Dataset\n",
    "from evaluate import load\n",
    "import bitsandbytes as bnb\n",
    "# Metriche di valutazione\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sistema e utility\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualizzazione\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\n",
    "    \"### Instruction:\\n\"\n",
    "    \"You are an expert software developer and bug triaging specialist. Your task is to predict whether a bug \"\n",
    "    \"will be resolved in LESS than 50 DAYS or MORE than 50 DAYS based on the provided bug details.\\n\\n\"\n",
    "    \n",
    "    \"- Output '0' if the bug will be resolved in LESS than 50 DAYS.\\n\"\n",
    "    \"- Output '1' if the bug will be resolved in MORE than 50 DAYS.\\n\\n\"\n",
    "    \n",
    "    \"Your response MUST be strictly either '0' or '1'. Do NOT include any additional text, explanations, formatting, symbols, or extra characters in your response.\\n\\n\"\n",
    "\n",
    "    \"### Input:\\n\"\n",
    "    \"Source: {source}\\n\"\n",
    "    \"Short Description: {short_desc}\\n\"\n",
    "    \"Priority: {priority}\\n\"\n",
    "    \"Severity: {bug_severity}\\n\"\n",
    "    #\"Estimated resolution time: {days_resolution}\\n\\n\" - questo potrebbe influenzare troppo il modello per la predizione\n",
    "\n",
    "    \"### Example Responses:\\n\"\n",
    "    \"Input: Source: KDE | Product: Payment System | Short Description: Critical security vulnerability found in authentication system | Priority: P1 | Severity: Critical\\n\"\n",
    "    \"Output: 0\\n\\n\"\n",
    "    \"Input: Source: OpenOffice | Product: UI Module | Short Description: UI glitch affecting low-impact visual elements in settings panel | Priority: P3 | Severity: Minor\\n\"\n",
    "    \"Output: 1\\n\\n\"\n",
    "\n",
    "    \"### Output: {label}\\n\"\n",
    ")\n",
    "num_val = \"1000\" #1000, 2000, 5000, 9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "caricamento del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = torch.float16 #altrimenti None\n",
    "load_in_4bit = True\n",
    "seed = 3407\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "model_name=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token = hf_token)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 35,127,296 || all params: 8,065,388,544 || trainable%: 0.4355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # Layer fondamentali per catturare relazioni tra token\n",
    "    # q_proj : \"Query projection\", v_proj: \"Value projection\", k_proj : \"Key projection\", o_proh: \"output projection\"\n",
    "    #target_modules=['q_proj', 'v_proj', 'k_proj','o_proj','gate_proj','up_proj','down_proj','lm_head','embedded_layers']\n",
    "    target_modules = ['q_proj', 'v_proj', 'gate_proj', 'up_proj', 'down_proj'] #forse lm_head non serve perchÃ¨ generiamo solo un singolo token\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formattazione del prompt con i dati del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'short_desc': 'Reset needs more explanation and an example',\n",
       " 'product': 'Identity Manager Designer',\n",
       " 'priority': 'P5 None',\n",
       " 'bug_severity': 'Enhancement',\n",
       " 'days_resolution': 435,\n",
       " 'comments': 'The Filter Editor lets you set attribute to reset The doc explains it a little but not enough to really understand what it is This is an important new feature that weve exposed in Spitfire and without a fuller explanation users probably wont dare to use it An example or use case for why you would use this would be really helpful Lee can you provide this information or an example Juliet Talk to Shon Vella for an example Thanks Bill Shouldnt hold 11 Marking 20 Ship We should look at adding this to the doc in Designer Add the following information The Reset option makes a data store the authoritative source of information For example if an employees addresses should only be changed in HR database then set the Reset option in the filter for this attribute When an address is changed in the email system and sent to the HR database the filter sends the information from the HR database back to the email system and the employees address is not changed Under Filter Editing the Filter Changing the Filter Setting in the attribute table under the Reset option I will close this bug once I add the help files into the build MArking public view Adding documentation keyword to doc bugs Marking Enh Checked the information into the build Add the following information The Reset option makes a data store the authoritative source of information For example if an employees addresses should only be changed in HR database then set the Reset option in the filter for this attribute When an address is changed in the email system and sent to the HR database the filter sends the information from the HR database back to the email system and the employees address is not changed Under Filter Editing the Filter Changing the Filter Setting in the attribute table under the Reset option Checked the information into the build Add the following information The Reset option makes a data store the authoritative source of information For example if an employees addresses should only be changed in HR database then set the Reset option in the filter for this attribute When an address is changed in the email system and sent to the HR database the filter sends the information from the HR database back to the email system and the employees address is not changed Under Filter Editing the Filter Changing the Filter Setting in the attribute table under the Reset option Regressed 0111',\n",
       " 'source': 'Novell',\n",
       " 'label': 1,\n",
       " 'text': \"### Instruction:\\nYou are an expert software developer. Your task is to predict whether a bug will be resolved in LESS than 50 DAYS or MORE than 50 DAYS based on the provided bug description and source of the bug.\\n\\n- Output 0 if the bug will be resolved in LESS than 50 DAYS.\\n- Output 1 if the bug will be resolved in MORE than 50 DAYS.\\n\\nYour response MUST be a single character: '0' or '1'. Do NOT include any additional text, explanations, or formatting. No symbols or extra characters should be included in the response.\\n\\n### Input:\\nSource: Novell\\nShort Description: Reset needs more explanation and an example\\n### Response: 1<|eot_id|>\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token  # Assicuriamoci di aggiungere il token EOS alla fine\n",
    "\n",
    "def formatting_prompts(examples, include_label=True):\n",
    "    texts = []\n",
    "    for source, short_desc, priority, bug_severity, label in zip(\n",
    "        examples[\"source\"], examples[\"short_desc\"], examples[\"priority\"], examples[\"bug_severity\"], examples[\"label\"]\n",
    "    ):\n",
    "        if include_label:\n",
    "            text = prompt_template.format(\n",
    "                source=source, \n",
    "                short_desc=short_desc,\n",
    "                priority=priority,\n",
    "                bug_severity=bug_severity,\n",
    "                label=label,  # La label viene passata solo se include_label=True\n",
    "            ) + EOS_TOKEN\n",
    "        else:\n",
    "            text = prompt_template.format(\n",
    "                source=source, \n",
    "                short_desc=short_desc,\n",
    "                priority=priority,\n",
    "                bug_severity=bug_severity,\n",
    "                label=\"\",  #  Non passiamo la label\n",
    "            ) + EOS_TOKEN\n",
    "        \n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "\n",
    "# Caricamento dataset\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": f\"../dataset_completo/balanced_datasets/balanced_train_{num_val}.csv\", \n",
    "        \"test\": f\"../dataset_completo/balanced_datasets/balanced_test.csv\", \n",
    "        \"val\": f\"../dataset_completo/balanced_datasets/balanced_validation.csv\" \n",
    "    },\n",
    ")\n",
    "\n",
    "# Formattiamo il dataset con il nuovo prompt\n",
    "# Applichiamo la funzione al dataset\n",
    "dataset[\"train\"] = dataset[\"train\"].map(lambda x: formatting_prompts(x, include_label=True), batched=True)\n",
    "dataset[\"val\"] = dataset[\"val\"].map(lambda x: formatting_prompts(x, include_label=False), batched=True)  # ðŸš¨ Label nascosta\n",
    "#dataset[\"test\"] = dataset[\"test\"].map(lambda x: formatting_prompts(x, include_label=False), batched=True)  # ðŸš¨ Label nascosta\n",
    "\n",
    "\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9000/9000 [00:00<00:00, 19955.70 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2250/2250 [00:00<00:00, 20201.87 examples/s]\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2810' max='2810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2810/2810 3:26:40, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>0.436573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.387529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.367181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.362700</td>\n",
       "      <td>0.348613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.334592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>0.320921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.307495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.296343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.313100</td>\n",
       "      <td>0.285027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.272477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.263639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.247801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.238026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.227889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.254800</td>\n",
       "      <td>0.219153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.209289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.196846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.188887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.183424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.177226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.172085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.169005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.162979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.161800</td>\n",
       "      <td>0.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.159220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.158559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.158172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.158113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=2810, training_loss=0.291064202615799, metrics={'train_runtime': 12403.3228, 'train_samples_per_second': 3.628, 'train_steps_per_second': 0.227, 'total_flos': 3.1195040796337766e+17, 'train_loss': 0.291064202615799, 'epoch': 4.992})\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "# Carichiamo la metrica di accuracy\n",
    "#accuracy_metric = load(\"accuracy\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # âœ… Fix padding issue\n",
    "    tokenizer.padding_side = \"right\"\n",
    "model.train() \n",
    "directory = f\"{model_name}\".split(\"/\")[-1].strip()\n",
    "# ðŸ”¹ Configurazione per l'addestramento (usando SFTConfig)\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=f\"{directory}_{num_val}_ft\",\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",  # Cambia se necessario\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,  #  PiÃ¹ epoche per adattare bene LoRA\n",
    "    gradient_accumulation_steps=4,  #  Ridotto per aggiornamenti piÃ¹ frequenti\n",
    "    evaluation_strategy=\"steps\",  #  Valutazione piÃ¹ frequente\n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,  #  Evita troppi checkpoint\n",
    "    learning_rate=5e-5,  #  Aumentato per migliorare adattamento\n",
    "    lr_scheduler_type=\"cosine\",  #  Cosine decay per convergenza piÃ¹ fluida\n",
    "    warmup_ratio=0.05,  # Warmup ridotto per velocizzare training\n",
    "    fp16=True,  #  Mantieni mixed precision\n",
    "    logging_steps=50,  #  Meno logging per ridurre overhead\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"val\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=sft_config,\n",
    "    packing= False,\n",
    ")\n",
    "\n",
    "# Avviamo il training!\n",
    "trainer_stats = trainer.train()\n",
    "print(trainer_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo i dati da salvare\n",
    "training_results = {\n",
    "    \"Dataset Size\": num_val,  # Numero di dati usati per il fine-tuning\n",
    "    \"Training Loss\": trainer_stats.training_loss,\n",
    "    \"Train Time (s)\": trainer_stats.metrics[\"train_runtime\"],\n",
    "    \"Steps\": trainer_stats.global_step,\n",
    "    \"Samples/sec\": trainer_stats.metrics[\"train_samples_per_second\"],\n",
    "    \"Steps/sec\": trainer_stats.metrics[\"train_steps_per_second\"]\n",
    "}\n",
    "\n",
    "# Carica dati precedenti se esiste giÃ  un file\n",
    "results_file = f\"{model_name}_fine_tuned_on_{num_val}/training_comparison.csv\"\n",
    "try:\n",
    "    df_results = pd.read_csv(results_file)\n",
    "except FileNotFoundError:\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "# Aggiungi nuovo risultato e salva\n",
    "df_results = df_results.append(training_results, ignore_index=True)\n",
    "df_results.to_csv(results_file, index=False)\n",
    "\n",
    "# Mostra la tabella aggiornata\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model_llama_3.1_8b_9000/tokenizer_config.json',\n",
       " './fine_tuned_model_llama_3.1_8b_9000/special_tokens_map.json',\n",
       " './fine_tuned_model_llama_3.1_8b_9000/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(f\"./fine_tuned_model_llama_3.1_8b_{num_val}\")\n",
    "tokenizer.save_pretrained(f\"./fine_tuned_model_llama_3.1_8b_{num_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
