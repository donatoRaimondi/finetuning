{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Torch e CUDA\n",
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Transformers e Training\n",
    "from transformers import (\n",
    "    TextStreamer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# Dataset e valutazione\n",
    "from datasets import load_dataset, Dataset\n",
    "from evaluate import load\n",
    "import bitsandbytes as bnb\n",
    "# Metriche di valutazione\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sistema e utility\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualizzazione\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\n",
    "    \"### Instruction:\\n\"\n",
    "    \"You are an expert software developer and bug triaging specialist. Your task is to predict whether a bug \"\n",
    "    \"will be resolved in LESS than 50 DAYS or MORE than 50 DAYS based on the provided bug details.\\n\\n\"\n",
    "    \n",
    "    \"- Output '0' if the bug will be resolved in LESS than 50 DAYS.\\n\"\n",
    "    \"- Output '1' if the bug will be resolved in MORE than 50 DAYS.\\n\\n\"\n",
    "    \n",
    "    \"Your response MUST be strictly either '0' or '1'. Do NOT include any additional text, explanations, formatting, symbols, or extra characters in your response.\\n\\n\"\n",
    "\n",
    "    \"### Input:\\n\"\n",
    "    \"Source: {source}\\n\"\n",
    "    \"Product: {product}\"\n",
    "    \"Short Description: {short_desc}\\n\"\n",
    "    \"Priority: {priority}\\n\"\n",
    "    \"Severity: {bug_severity}\\n\"\n",
    "    #\"Estimated resolution time: {days_resolution}\\n\\n\" - questo potrebbe influenzare troppo il modello per la predizione\n",
    "\n",
    "    \"### Example Responses:\\n\"\n",
    "    \"Input: Source: KDE | Product: Payment System | Short Description: Critical security vulnerability found in authentication system | Priority: P1 | Severity: Critical\\n\"\n",
    "    \"Output: 0\\n\\n\"\n",
    "    \"Input: Source: OpenOffice | Product: UI Module | Short Description: UI glitch affecting low-impact visual elements in settings panel | Priority: P3 | Severity: Minor\\n\"\n",
    "    \"Output: 1\\n\\n\"\n",
    "\n",
    "    \"### Output: {label}\\n\"\n",
    ")\n",
    "num_val = \"2000\" #1000, 2000, 5000, 9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "caricamento del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = torch.float16 #altrimenti None\n",
    "load_in_4bit = True\n",
    "seed = 3407\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "model_name=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token = hf_token)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 35,127,296 || all params: 8,065,388,544 || trainable%: 0.4355\n"
     ]
    }
   ],
   "source": [
    "# Peft -  Parameter Efficient Fine Tuning\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # Layer fondamentali per catturare relazioni tra token\n",
    "    # q_proj : \"Query projection\", v_proj: \"Value projection\", k_proj : \"Key projection\", o_proh: \"output projection\"\n",
    "    #target_modules=['q_proj', 'v_proj', 'k_proj','o_proj','gate_proj','up_proj','down_proj','lm_head','embedded_layers']\n",
    "    target_modules = ['q_proj', 'v_proj', 'gate_proj', 'up_proj', 'down_proj'] #forse lm_head non serve perchè generiamo solo un singolo token\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formattazione del prompt con i dati del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1998 examples [00:00, 57397.98 examples/s]\n",
      "Generating test split: 2250 examples [00:00, 59911.02 examples/s]\n",
      "Generating val split: 2250 examples [00:00, 64019.54 examples/s]\n",
      "Map: 100%|██████████| 1998/1998 [00:00<00:00, 113707.18 examples/s]\n",
      "Map: 100%|██████████| 2250/2250 [00:00<00:00, 115494.66 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'short_desc': 'i965 BisectedOglc apierrornegativeglEvalMesh fails',\n",
       " 'product': 'Mesa',\n",
       " 'priority': 'high',\n",
       " 'bug_severity': 'major',\n",
       " 'days_resolution': 28,\n",
       " 'comments': 'System Environment Arch x8664 Platform Ivyybridge Libdrmmasterlibdrm24413g303ca37e722e68900cb7eb43ddbef8069b0c711b Mesamaster85c2e99039394292474b1a84e3dcb2fee30a0836 Xservermasterxorgserver1139990136g70b127c9f1c53bdb42f078265e67f76b464deae2 Xf86videointelmaster2201914g10f549332e315cfe2cc86aadab94a95ae6757c34 Cairomastered2fa6b16b03fccc3e21598cdb9157cbcebd1d37 Libvastaging21649988d6b532cc96f633db017d1e4369f640e9 Libvainteldriverstagingd206b47a6ac86c089149ecd71b01eea6ebda5796 Kerneldrmintelnightly 418ccc855c65e0e90f81012bbc34de20b9f45cbd Bug detailed description It fails on ironlake sandybridge and ivybridge with mesa master branch It works well on mesa 90 branch Bisect shows a9754793dab4b24c09cae21c29f902ce0e53319a is the first bad commit commit a9754793dab4b24c09cae21c29f902ce0e53319a Author Eric Anholt AuthorDate Wed Jan 16 162038 2013 0800 Commit Eric Anholt CommitDate Mon Jan 21 212647 2013 0800 mesa Drop manual checks for outside beginend We now have a separate dispatch table for beginend that prevent these functions from being entered during that time The ASSERTOUTSIDEBEGINENDWITHRETVALs are left because I dont want to change any return values or introduce new erroronly stubs at this point output Intel OpenGL Conformance Test Version ENG Jan 22 2013 155655 CLI options echo oglconform z suite all v 2 test apierror negativeglEvalMesh Window will be recreated 2 times Window 0 will run 1 testcases on config with id 132 Window 1 will run 1 testcases on config with id 110 Total of 2 testcases will be executed Setup Report Verbose level 2 Path inactive Visual Report for ID 132 32 bits ID ACCELERADB RENDT SURFT CBUFT BUFS REDS 132 1 1 gl wipbpx rgba 32 8 GREENS BLUES ALPHAS DEPTHS STENCS ACCUMS SPLBUF SAMPLES 8 8 8 24 8 64 0 0 SRGB TEXRGB TEXRGBACAVEAT SWAP MPBUFWMPBUFHMPBUFP 0 0 0 slow undef 0 0 0 OpenGL Report Vendor Intel Open Source Technology Center Renderer Mesa DRI IntelR Ivybridge Desktop Version 30 Mesa 91devel git85c2e99 30 GLSL Version 130 Context Flags None API error code test apierror test 430 negativeglEvalMesh subcase TestNegativeglEvalMesh1399 returned no error should return GLINVALIDOPERATION TestNegativeglEvalMesh1410 returned no error should return GLINVALIDOPERATION API error code test apierror test 430 negativeglEvalMesh subcase TestNegativeglEvalMesh1399 returned no error should return GLINVALIDOPERATION TestNegativeglEvalMesh1410 returned no error should return GLINVALIDOPERATION 430 negativeglEvalMesh subcase failed API error code test apierror test failed 1 of 1 subcases Intel Conformance failed Total Passed 0 Total Failed 2 Total Not run 0 Reproduce steps 1 xinit 2 oglconform z suite all v 2 test apierror negativeglEvalMesh It also fails on mesa 91 branch Patch posted to the mesadev mailing list This is fixed on Mesa master by the commit below It has also be picked to the 91 branch 6ff7080 commit 8b586322e71d5ad0ce95d0fbcbfeb4df13f65040 Author Ian Romanick Date Tue Feb 19 152357 2013 0800 mesa Dont install glEvalMesh in the beginend dispatch table NOTE This is a candidate for the 91 branch Signedoffby Ian Romanick Bugzilla Reviewedby Eric Anholt Verified on mesa master and 91 branch',\n",
       " 'source': 'FreeDesktop',\n",
       " 'label': 0,\n",
       " 'text': \"### Instruction:\\nYou are an expert software developer and bug triaging specialist. Your task is to predict whether a bug will be resolved in LESS than 50 DAYS or MORE than 50 DAYS based on the provided bug details.\\n\\n- Output '0' if the bug will be resolved in LESS than 50 DAYS.\\n- Output '1' if the bug will be resolved in MORE than 50 DAYS.\\n\\nYour response MUST be strictly either '0' or '1'. Do NOT include any additional text, explanations, formatting, symbols, or extra characters in your response.\\n\\n### Input:\\nSource: FreeDesktop\\nProduct: MesaShort Description: i965 BisectedOglc apierrornegativeglEvalMesh fails\\nPriority: high\\nSeverity: major\\n### Example Responses:\\nInput: Source: KDE | Product: Payment System | Short Description: Critical security vulnerability found in authentication system | Priority: P1 | Severity: Critical\\nOutput: 0\\n\\nInput: Source: OpenOffice | Product: UI Module | Short Description: UI glitch affecting low-impact visual elements in settings panel | Priority: P3 | Severity: Minor\\nOutput: 1\\n\\n### Output: 0\\n<|eot_id|>\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token  # Assicuriamoci di aggiungere il token EOS alla fine\n",
    "\n",
    "def formatting_prompts(examples, include_label=True):\n",
    "    texts = []\n",
    "    for source, product, short_desc, priority, bug_severity, label in zip(\n",
    "        examples[\"source\"],examples[\"product\"], examples[\"short_desc\"], examples[\"priority\"], examples[\"bug_severity\"], examples[\"label\"]\n",
    "    ):\n",
    "        if include_label:\n",
    "            text = prompt_template.format(\n",
    "                source=source,\n",
    "                product=product,\n",
    "                short_desc=short_desc,\n",
    "                priority=priority,\n",
    "                bug_severity=bug_severity,\n",
    "                label=label,  # La label viene passata solo se include_label=True\n",
    "            ) + EOS_TOKEN\n",
    "        else:\n",
    "            text = prompt_template.format(\n",
    "                source=source,\n",
    "                product=product, \n",
    "                short_desc=short_desc,\n",
    "                priority=priority,\n",
    "                bug_severity=bug_severity,\n",
    "                label=\"\",  #  Non passiamo la label\n",
    "            ) + EOS_TOKEN\n",
    "        \n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "\n",
    "# Caricamento dataset\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": f\"../dataset_completo/balanced_datasets/balanced_train_{num_val}.csv\", \n",
    "        \"test\": f\"../dataset_completo/balanced_datasets/balanced_test.csv\", \n",
    "        \"val\": f\"../dataset_completo/balanced_datasets/balanced_validation.csv\" \n",
    "    },\n",
    ")\n",
    "\n",
    "# Formattiamo il dataset con il nuovo prompt\n",
    "# Applichiamo la funzione al dataset\n",
    "dataset[\"train\"] = dataset[\"train\"].map(lambda x: formatting_prompts(x, include_label=True), batched=True)\n",
    "dataset[\"val\"] = dataset[\"val\"].map(lambda x: formatting_prompts(x, include_label=False), batched=True)  # 🚨 Label nascosta\n",
    "#dataset[\"test\"] = dataset[\"test\"].map(lambda x: formatting_prompts(x, include_label=False), batched=True)  # 🚨 Label nascosta\n",
    "\n",
    "\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 1998/1998 [00:00<00:00, 13133.70 examples/s]\n",
      "Map: 100%|██████████| 2250/2250 [00:00<00:00, 13293.38 examples/s]\n",
      "/home/raffaeleterracino/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 27/625 01:47 < 42:47, 0.23 it/s, Epoch 0.21/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "# Carichiamo la metrica di accuracy\n",
    "#accuracy_metric = load(\"accuracy\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # ✅ Fix padding issue\n",
    "    tokenizer.padding_side = \"right\"\n",
    "model.train() \n",
    "directory = f\"{model_name}\".split(\"/\")[-1].strip()\n",
    "# 🔹 Configurazione per l'addestramento (usando SFTConfig)\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=f\"{directory}_{num_val}_ft\",\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",  # Cambia se necessario\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,  #  Più epoche per adattare bene LoRA\n",
    "    gradient_accumulation_steps=4,  #  Ridotto per aggiornamenti più frequenti\n",
    "    evaluation_strategy=\"steps\",  #  Valutazione più frequente\n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,  #  Evita troppi checkpoint\n",
    "    learning_rate=5e-5,  #  Aumentato per migliorare adattamento\n",
    "    lr_scheduler_type=\"cosine\",  #  Cosine decay per convergenza più fluida\n",
    "    warmup_ratio=0.05,  # Warmup ridotto per velocizzare training\n",
    "    fp16=True,  #  Mantieni mixed precision\n",
    "    logging_steps=50,  #  Meno logging per ridurre overhead\n",
    "    metric_for_best_model=\"eval_loss\",  # 👈 Assicura che il modello salvi in base alla Validation Loss\n",
    "    greater_is_better=False  # 👈 Perché una loss minore è meglio\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"val\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=sft_config,\n",
    "    packing= False,\n",
    ")\n",
    "\n",
    "# Avviamo il training!\n",
    "trainer_stats = trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(trainer_stats)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Definiamo le metriche da salvare\n",
    "training_results = {\n",
    "    \"Dataset Size\": num_val,  # Numero di dati usati per il fine-tuning\n",
    "    \"Training Loss\": trainer_stats.training_loss,  # Training Loss\n",
    "    \"Train Time (s)\": trainer_stats.metrics[\"train_runtime\"],  # Tempo di addestramento\n",
    "    \"Steps\": trainer_stats.global_step,  # Numero di passi (steps)\n",
    "    \"Samples/sec\": trainer_stats.metrics[\"train_samples_per_second\"],  # Campioni al secondo\n",
    "    \"Steps/sec\": trainer_stats.metrics[\"train_steps_per_second\"],  # Passi al secondo\n",
    "    \"Validation Loss\": eval_results.get(\"eval_loss\", None),  # Valutazione della loss\n",
    "}\n",
    "\n",
    "# Definiamo il file di destinazione per i risultati\n",
    "results_file = f\"{model_name}_fine_tuned_on_{num_val}/training_comparison.csv\"\n",
    "\n",
    "# Converti il dizionario in un DataFrame\n",
    "training_results_df = pd.DataFrame([training_results])  # Passiamo una lista contenente il dizionario\n",
    "\n",
    "# Assicura che la cartella esista prima di salvare\n",
    "Path(results_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salva il DataFrame nel file CSV, sovrascrivendo se già esistente\n",
    "training_results_df.to_csv(results_file, index=False)\n",
    "\n",
    "# Mostra la tabella aggiornata\n",
    "print(training_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f\"{model_name}\".split(\"/\")[-1].strip().lower()\n",
    "\n",
    "model.save_pretrained(f\"./fine_tuned_model_{directory}_{num_val}\" )\n",
    "tokenizer.save_pretrained(f\"./fine_tuned_model_{directory}_{num_val}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
